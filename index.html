<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Now you see me!">
  <meta property="og:title" content="Now you see me!"/>
  <meta property="og:description" content="A framework for obtaining class-relevant saliency maps"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/mug.png" />
  <meta property="og:image:width" content="3046"/>
  <meta property="og:image:height" content="1839"/>


  <meta name="twitter:title" content="Now you see me!">
  <meta name="twitter:description" content="A framework for obtaining class-relevant saliency maps">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Now you see me!</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <!-- Add this to your <head> section -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Now you see me! A framework for obtaining class-relevant saliency maps</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://nilspwalter.github.io/" target="_blank">Nils Phillipp Walter</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://vreeken.eu/" target="_blank">Jilles Vreeken</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://explainablemachines.com/" target="_blank">Jonas Fischer</a><sup>2</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>CISPA Helmholtz Center for Information Security, </span>
                    <span class="author-block"><sup>2</sup>Max Planck Institute for Informatics</span>
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>-->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="static/pdfs/main.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link 
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>-->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/nilspwalter/var" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2503.07346" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image -->

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="blend-img-item">
        <!-- Your image here -->
        <img src="static/images/main.jpg" alt="Banner image" class="center-image blend-img-background" style="max-width: 100%; height: auto;">
      </div>
      <p  style="margin-top: 0.1rem; font-size: 1rem;">
        <em><span style="font-variant: small-caps;">Var</span> Attributions.</em> <span style="font-variant: small-caps;">Var</span> attributions are <strong>object-specific</strong> and visually ground correct target objects. <span style="font-variant: small-caps;">Var</span> attributions are <strong>instance-specific</strong>, identifying features that are relevant on a by-part-basis. <span style="font-variant: small-caps;">Var</span> attributions are <strong>class-discriminative</strong>, yielding features that separate closely related classes. <span style="font-variant: small-caps;">Var</span> attributions reveal <strong>shared concepts</strong> between closely related classes. In contrast, vanilla attribution methods (here GBP) do not show these properties.
      </p>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Neural networks are part of daily-life decision-making, including in high-stakes settings where understanding and transparency are key. Saliency maps have been developed to gain understanding into which input features neural networks use for a specific prediction. Although widely employed, these methods often result in overly general saliency maps that  fail to identify the specific information that triggered the classification.
            In this work, we suggest a framework, called <span style="font-variant: small-caps;">Var</span>,  that allows to incorporate attributions across classes to arrive at saliency maps that actually capture the class-relevant information.
            On established benchmarks for attribution methods, including the grid-pointing game and randomization-based sanity checks, we show that our framework heavily boosts the performance of standard saliency map approaches. It is, by design, agnostic to model architectures and attribution methods and now allows to identify the distinguishing and shared features used for a model prediction.          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3"><span style="font-variant: small-caps;">Var</span> is a plug-and-play framework</h2>
         <p>
              <img src="static/images/framework.jpg"Directional Weight Score" class="blend-img-background center-image" style="max-width: 100%; height: auto;">
            </p>
            <p>
              We show <span style="font-variant: small-caps;">Var</span> augmenting different attribution methods (columns) and architectures (rows)
              for detecting zebras (left) resp. bisons (right) in the original image (middle), using Gradient Backpropagation (GPB), Integrated
              Gradients (IG), and GradCAM, for respectively ResNet50 and ViT. <span style="font-variant: small-caps;">Var</span> seemlesly integrates with various attribution methods
              and architectures.
            </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Math section -->
<section class="section hero is-small is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">... can be described three steps</h2>
          <div class="math-description">
            <!-- Step 1 -->
            <div id="math-step-1" class="highlight-section step1-highlight" data-connection="math-step-1">
              <h4>Step 1: Initial Attribution</h4>
              <p>First, compute attribution maps for each class c ∈ {1, ..., K}:</p>
              <div class="formula">$$A_c = \text{Attribution}(x, c)$$</div>
              <p>Where: x is the input, K is the number of classes, A<sub>c</sub> is the attribution map for class c</p>
              <div class="tooltip-text">Computes attribution maps for each class</div>
            </div>
          
            <!-- Step 2 -->
            <div id="math-step-2" class="highlight-section step2-highlight" data-connection="math-step-2">
              <h4>Step 2: Pixel-wise Softmax</h4>
              <p>Compute softmax across classes for each pixel position (i,j):</p>
              <div class="formula">$$M_c(i, j) = \frac{e^{A_c(i,j)}}{\sum_{k=1}^{K} e^{A_k(i,j)}}$$</div>
              <div class="tooltip-text">Creates importance weighting using softmax</div>
            </div>
          
            <!-- Step 3 -->
            <div id="math-step-3" class="highlight-section step3-highlight" data-connection="math-step-3">
              <h4>Step 3: Final Attribution</h4>
              <p>The final attribution for class c is computed as:</p>
              <div class="formula">$$V_c = A_c \odot M_c \odot \mathbb{1}_{M_c - \frac{1}{K} > 5\times10^{-3}}$$</div>
              <p>Where: ⊙ denotes element-wise multiplication, 𝟙 is the indicator function, K is the number of classes, 5×10<sup>-3</sup> is the threshold parameter</p>
              <div class="tooltip-text">Applies threshold and computes final attribution</div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Code section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">... and implemented in few lines of code</h2>
          <div class="code-editor">
            <div class="code-header">
              <div class="filename">contrastive_attribution.py</div>
              <div class="window-controls">
                <span class="control red"></span>
                <span class="control yellow"></span>
                <span class="control green"></span>
              </div>
            </div>
            <div class="code-body">
              <pre><code><span class="keyword">def</span> <span class="function">attribute</span>(<span class="self">self</span>, img, target, class_indices):
    <span class="docstring">"""Compute contrastive attribution for target class."""</span>
    
    <span id="code-step-1" class="highlight-section step1-highlight" data-connection="code-step-1"><span class="comment"># Compute attributions for all classes at once</span>
    attributions <span class="operator">=</span> torch.stack([
        <span class="self">self</span>.base_attribute_fn(img, target<span class="operator">=</span>class_idx).detach()
        <span class="keyword">for</span> class_idx <span class="keyword">in</span> class_indices
    ], dim<span class="operator">=</span>0)</span>
    
    <span id="code-step-2" class="highlight-section step2-highlight" data-connection="code-step-2"><span class="comment"># Apply softmax to get importance weighting</span>
    mask <span class="operator">=</span> torch.nn.functional.softmax(<span class="num">10.0</span> <span class="operator">*</span> attributions, dim<span class="operator">=</span><span class="num">0</span>)</span>
    
    <span class="comment"># Find target index</span>
    target_idx <span class="operator">=</span> class_indices.index(target)
    
    <span id="code-step-3" class="highlight-section step3-highlight" data-connection="code-step-3"><span class="comment"># Compute final attribution with thresholding</span>
    threshold <span class="operator">=</span> <span class="num">1.0</span> <span class="operator">/</span> len(class_indices)
    indicator <span class="operator">=</span> (mask[target_idx] <span class="operator">-</span> threshold) <span class="operator">></span> <span class="self">self</span>.tau
    <span class="keyword">return</span> attributions[target_idx] <span class="operator">*</span> mask[target_idx] <span class="operator">*</span> indicator</span></code></pre>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Include the JavaScript at the end of the body -->
<script>
document.addEventListener('DOMContentLoaded', function() {
  // Set up connections between math steps and code parts
  const connections = [
    {
      math: 'math-step-1',
      code: 'code-step-1',
      tooltip: 'Computation of attribution maps'
    },
    {
      math: 'math-step-2',
      code: 'code-step-2',
      tooltip: 'Application of softmax for importance weighting'
    },
    {
      math: 'math-step-3',
      code: 'code-step-3',
      tooltip: 'Thresholding and final attribution calculation'
    }
  ];

  // Set up bidirectional highlighting
  connections.forEach(function(connection) {
    const mathElement = document.getElementById(connection.math);
    const codeElement = document.getElementById(connection.code);
    
    if (mathElement && codeElement) {
      // Add mouse enter event to math element
      mathElement.addEventListener('mouseenter', function() {
        mathElement.classList.add('active');
        codeElement.classList.add('active');
      });
      
      // Add mouse leave event to math element
      mathElement.addEventListener('mouseleave', function() {
        mathElement.classList.remove('active');
        codeElement.classList.remove('active');
      });
      
      // Add mouse enter event to code element
      codeElement.addEventListener('mouseenter', function() {
        mathElement.classList.add('active');
        codeElement.classList.add('active');
      });
      
      // Add mouse leave event to code element
      codeElement.addEventListener('mouseleave', function() {
        mathElement.classList.remove('active');
        codeElement.classList.remove('active');
      });
    }
  });

  // Optional: Add scroll into view functionality
  document.querySelectorAll('.highlight-section').forEach(function(section) {
    section.addEventListener('click', function() {
      const connectionId = this.getAttribute('data-connection');
      const targetId = connectionId.startsWith('math') ? 
        connectionId.replace('math', 'code') : 
        connectionId.replace('code', 'math');
      
      const targetElement = document.getElementById(targetId);
      if (targetElement) {
        targetElement.scrollIntoView({ behavior: 'smooth', block: 'center' });
      }
    });
  });
});
</script>


<section class="section hero is-small is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3"><span style="font-variant: small-caps;">Var</span> improves on the grid pointing game</h2>
          <p>
            We evaluate <span style="font-variant: small-caps;">Var</span> using the grid pointing game with a 2×2 grid of random ImageNet validation images (Quad-ImageNet), consisting of 12,500 evaluation images.
            <span style="font-variant: small-caps;">Var</span>  substantially improves localization performance across all attribution methods. For ResNet50, we observe gains in Region Attribution (RA), which quantifies what portion of the total attribution weight falls within the target region, ranging from +0.16 to +0.54 with an average increase of +0.24. GradCAM with Var shows particularly strong performance, achieving an RA of 0.92, F1 score of 0.81, and IoU improvement from 0.41 to 0.71. Precision increases on average by +0.31.
            Our framework not only improves localization of distinguishing features but also recovers common features of closely related classes. GBP precision improved from 0.25 to 0.83, and Guided GradCAM from 0.39 to 0.84 when enhanced with  <span style="font-variant: small-caps;">Var</span> .
          </p> 
          <!-- Use a relative positioned container for the image and labels -->
          <div style="position: relative; margin-top: 40px;"> <!-- Add margin-top for space below the title -->
            <!-- Labels positioned relative to this container -->
            <div style="position: absolute; top: -30px; left: 30%; transform: translateX(-50%); padding: 5px; border-radius: 0px;">Integrated Gradients</div>
            <div style="position: absolute; top: -30px; left: 58%; transform: translateX(-50%);  padding: 5px; border-radius: 4px;  ">Guided Backprop</div>
            <div style="position: absolute; top: -30px; left: 86%; transform: translateX(-50%); padding: 5px; white-space: nowrap;">Input x Gradients</div>
            
            <!-- The image -->
            <img src="static/images/grid-t.png" class="blend-img-background center-image" style="max-width: 100%; height: auto;">
          </div>
          

        </div>
      </div>
    </div>
  </div>
</section>


<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3"><span style="font-variant: small-caps;">Var</span> finds actionable class-specific features</h2>
          <p>
            <span style="font-variant: small-caps;">Var</span> attributions, in contrast to the baselines, capture the specific class-relevant features. Our ablation experiments demonstrate how <span style="font-variant: small-caps;">Var</span> can surgically modify images to change model predictions by removing only the most discriminative features.
            For the porcupine image, removing class-specific features changes the prediction to another class entirely. This demonstrates that <span style="font-variant: small-caps;">Var</span> precisely identifies the distinctive features that separate a porcupine from similar animals. With the cougar image, removing just a single distinctive feature - the ear - significantly increases the model's uncertainty, showing that <span style="font-variant: small-caps;">Var</span> correctly identifies this feature as crucial for the model's confident classification.
These examples illustrate how Var attributions allow for surgical removal of information from the image, rather than destroying all content. By targeting only the discriminative features identified by <span style="font-variant: small-caps;">Var</span>, we can manipulate the model's output distribution, shwoing that these highly relevant features. 
          </p>
         <p>
              <img src="static/images/cr.jpg"Directional Weight Score" class="blend-img-background center-image" style="max-width: 100%; height: auto;">
            </p>

        </div>
      </div>
    </div>
  </div>
</section>


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content is-light">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{walter2025now,
        title={Now you see me! A framework for obtaining class-relevant saliency maps},
        author={Walter, Nils Philipp and Vreeken, Jilles and Fischer, Jonas},
        journal={arXiv preprint arXiv:2503.07346},
        year={2025}
}
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>. <a href="https://nilspwalter.github.io/impressum/">Impressum</a>
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
